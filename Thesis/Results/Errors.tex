% !TEX root = ../Thesis.tex

\subsection{Error messages (M)}
\label{results:errors}

\subsubsection{Error message qualification}
The user friendliness and correctness of an error message is a subjective topic and therefore we need to start with a definition to objectively judge the quality of an error message.
After analyzing the current Ampersand parser error messages, we identified the following objective aspects of an Ampersand parser error message:
%
\begin{description}
	\item [Position]
	Each error messages is accompanied with the correct position (file, line number and column) of where the error was found.
	\item [Accuracy]
	The accuracy of an error message is measured based upon the following characteristics:
	\begin{enumerate}
		\item	\textbf{\small How does the provided error description exactly outlines the discovered error:}
				Providing the user with a good description of the encountered syntax issue will support a fast error resolution.
				When the issue is vaguely described without pinpointing the exact issue, the error resolution will be time consuming.
		\item	\textbf{\small Pinpointing the correct error}:
				An error can invoke multiple subsequent issues. 
				These issues are however irrelevant for the user and the Ampersand parser should provide the exact origin of the issues.
		\item	\textbf{\small Quality of the hint:}
			The parser provides a hint for a solution together with the error message to support the user with the error resolution.
	\end {enumerate}
    \item[Conciseness]
	Providing a good error description is one thing, but this one message can be hidden between several other error messages that result from the initial error.
	It is unlikely that users will easily find the exact originating issue in their source file when they are overwhelmed with a multitude of error messages. % using plural to avoid repeating his/her
\end {description}
%
Based on the objective Ampersand parser error characteristics, we defined the following definition to distinguish between good, bad and average error messages:
%
\begin{description}
	\item [Bad error message] A message is considered to be bad if one of the criteria blow is fulfilled:
		\begin{description}
			\item [Position]
			The position has a deviation of more then 1 line or 10 column positions from where the actual error is made.
			\item [Accuracy]~
				\begin{itemize}
					\item 	The provided error description is useless for the user to determine the actual error.
					\item 	The provided error description is not appointing the main, originating error without any correlation towards this main error.
				\end {itemize}
			\item[Conciseness]
			More then distinct 3 errors are mentioned by the Ampersand parser.
		\end {description}
	\item [Average error message] A message is considered to be of average quality if one of the criteria blow is fulfilled:
		\begin{description}
			\item [Position]
			The position has a deviation between 5 and 10 columns positions from where the actual error is made.
			\item [Accuracy]~
				\begin{itemize}
					\item 	The provided error description is not an exact description of the error but provides however useful information to discover the actual issue.
					\item 	The provided error description is not appointing the main, originating error but the link to the actual error can be discovered based on the provided information.
					\item 	The provided hint is incorrect.
				\end {itemize}
			\item[Conciseness]
			2 or 3 errors are mentioned by the Ampersand parser.
		\end {description}
		
	\item [Good error message] We can state that any error message being not bad nor average is good.
\end {description}

\subsubsection{Gathering process}

To support the as-is analysis, an exhaustive list of all possible error messages is created.
This as-is analysis will be used as a reference base to verify the implementation of the new error mechanism with Parsec.
The errors are invoked by simulating all possible syntax errors that will invoke an error within the Ampersand parser.
Each syntax statement is therefore manipulated, introducing one specific error per time, and the resulting error message is then recorded together with the actual erroneous statement.
The exact same statements are afterwards pushed through the new parser, making it possible to make a quantitative `before and after' analysis.
Special attention is given to avoid redundant errors that could influence the quantitative analysis. 
An example of such an redundant error is the use of a capital letter in defining a specific reference. 
Although these references are used in several syntax statements, there is only one procedure in the parser to check all references starting with a capital letter.
An improvement in the error message of this check may only be taken into account one time.

\subsubsection{Results}
After the thorough analysis of the old and new Ampersand parsers, the results are summarized in \autoref{tab:error-messages-results}.
The actual error list, containing the syntax statements with the corresponding error messages, is available as an appendix to this document.

% Please add the following required packages to your document preamble:
% \usepackage[table,xcdraw]{xcolor}
% If you use beamer only pass "xcolor=table" option, i.e. \documentclass[xcolor=table]{beamer}
\begin{table}[h]
  \centering
	\begin{tabular}{llrlr}
    Error quality  & \multicolumn{2}{c}{Old parser} & \multicolumn{2}{c}{New parser} \\
		Good           & 19          & 22,35\%          & 70          & 82,35\%          \\
		Average        & 18          & 21,18\%          & 14          & 16,47\%          \\
		Bad            & 48          & 56,47\%          & 1           &  1,18\%          \\
		\rowcolor[HTML]{BBBBBB}
		\textbf{Total} & \textbf{85} & \textbf{100,00\%} & \textbf{85} & \textbf{100,00\%}
	\end{tabular}
  \caption{Error message comparison results}
  \label{tab:error-messages-results}
\end{table}

The table clearly visualizes that there indeed was an issue with the error messages generated by the old Ampersand parser.
By implementing the new parser, an improvement of 360\% is made towards the creation of good error messages in which 82\% of the generated error messages are good, compared to 22\% in the old Parser.

One bad error message remains in the system.
After analysis, the resolution of this remaining bad error would require too much effort, hence increased complexity, compared to the value gain.
The error in question is thrown when the \texttt{Meta} statement is used with only one string value. 
Given the simple structure of the notation, we assume that the reference to the line number of the \texttt{Meta} is sufficient although the error message is unclear.
Therefore, this message is kept as is.

TODO: What is the effort to improve the average errors? How bad are they, really? Maybe we should rename average to `acceptable'.

General remarks and highlights:
 \begin{itemize}
	\item 	If the error qualification was defined in a less strict way, the numbers would be slightly different as some bad errors would be judged as being average. 
		In the comparison between the old and new parser, the exact same qualification method is used while the syntax issue was, as well, identical.
		Due to this approach, we can conclude that the achieved results are justified.
	\item 	Error positioning was already correct in the old Ampersand parser, this is maintained in the new parser.
	\item 	The principle of Parsec to end parsing after the first error is found to have a massive improvement on the bad error messages due the conciseness issues.
		Nearly 50\% of the average and bad messages changed to good error messages just due to this principle.
	\item 	Some error messages were extremely elaborated due to which the standard Windows command prompt was unable to fully show the error message.
\end {itemize}

\subsubsection{Conclusion}
Based on the defined error qualification method, we can clearly conclude that the implementation of the new Ampersand parser has a very positive effect on the error messages quality.
The percentage of good errors is now on an acceptable level and the remaining errors are, except for 1, of average quality, still giving valuable information used for error resolution.

To avoid the risk of additional complexity in the parser code, thus decreasing the code maintainability, we judged that this result is  the best compromise between error message quality and maintainability.
