% !TEX root = ../Thesis.tex

\subsection{Scanner}
\label{analysis:lexer}
As part of the system analysis, we also analyzed the existing scanner/lexer.
The scanner is responsible to split up the input stream into tokens.
Tokens are atomic and categorized pieces of information from the input string that can be recognized by the parser.

The following improvement points were identified after the analysis:
\begin{description}
  \item[Dispersed error messages]
    The error messages produced by the lexer are of good quality.
    Each error message is, however, defined directly within the corresponding lexer function making the maintenance harder.
  \item[Complex token structure]
    The token structure is complex and confusing (the structure is given below).
    Two values are present in the token, of which one (\code{val1}) is never used.
    There is no distinction between the values used to identify the content of the token and the ones to determine the position of the token, i.e. they are in the same data type.
  \item[Module structuring]
    In the lexer, the actual lexing functions are intermingled with data types, supporting functions and error message texts.
    This makes the lexer harder to understand and to maintain.
  \item[Language support]
    The errors are returned in English only; no multilingual support is available (or easy to implement).
  \item[No support for warnings]
    The lexer can only return errors.
    Warnings are not supported.
  \item[Strings only]
    Token values are stored as strings for all types, with no conversion of values, e.g. integers.
  \item[Lacking documentation]
    There was no documentation available on how the lexer was designed and structured.
\end{description}

The tokens from the old parser are represented by the following data type.
Note that the comments have been added by us, only in this document.

\begin{haskell}
data Token = Tok
 { tp'  :: TokenType -- Identification of the token type
 , val1 :: String    -- This string argument is not used in the lexer.
                     -- For keywords it is filled in but never read.
 , val2 :: String    -- The actual token content, stored as a string
 , pos  :: !Pos      -- Line and column number
 , file :: !Filename -- File name in which the token is located.
 }

data TokenType
  = TkSymbol    -- ^ Single character symbol
  | TkVarid     -- ^ Lower case identifier
  | TkConid     -- ^ Upper case identifier
  | TkKeyword   -- ^ Keyword
  | TkOp        -- ^ Operator
  | TkString    -- ^ String
  | TkExpl      -- ^ Explanation
  | TkAtom      -- ^ Atom
  | TkChar      -- ^ Single character
  | TkInteger8  -- ^ Octal integer
  | TkInteger10 -- ^ Decimal integer
  | TkInteger16 -- ^ Hexadecimal integer
  | TkTextnm    -- ^ Unused
  | TkTextln    -- ^ Unused
  | TkSpace     -- ^ Unused
  | TkError     -- ^ Unused
  deriving (Eq, Ord)
\end{haskell}
