% !TEX root = ../Parsing.tex

\section{Haskell parsing libraries}
\label{sec:libraries}

\subsection{Parsing remarks}
\dict{Lexical analysis}{Separating text into tokens}%
\dict{Lexer}{Software that does the lexical analysis}%
\dict{Alex}{Lexer included in the Haskell Platform}%
Parsing is sometimes divided into two stages: lexical analysis (separating the source text into tokens) and parsing itself (constructing a parse tree from these tokens).
Tools such as the ones analyzed here can perform both lexical analysis and parsing.
However, sometimes the tools can be more efficient when supported by a separate Lexer (e.g. Alex).

Grammars associated with a formal language are described as a set of production rules.
Since these rules are formally defined, a series of mathematical constructions can be used to manipulate and describe the grammar.

\dict{ADL}{Ampersand Definition Language}%
\dict{BNF}{Backus-Naur Form, a meta-syntax notation for expressing context-free grammars}%
\dict{EBNF}{Extended Backus-Naur Form, an extension on BNF}%
The Ampersand Definition Language (ADL) is specified in a grammar in the Extended Backus-Naur Form (EBNF).
Even though it is known that the grammar is not up to date, this article assumes the updated version will not be fundamentally different from the specified grammar.

\subsection{Generators vs. combinators}
\dict{DSL}{Domain specific language}%
Generally, there are two options for constructing a parser:
The first option is to construct the parser in the language of choice, i.e. Haskell for this project.
Another possibility is to use a domain-specific-language (DSL) to describe the grammar, and let separate software generate the actual parsing code.
The two approaches and their advantages and disadvantages are described in this section.

\subsubsection{Parsing libraries}
\dict{EDSL}{Embedded Domain Specific Language}%
When programmers go down the path of building a parser directly in Haskell, building up a set of functions that support parsing is a natural consequence.
Although it is possible to build these functions for each and every project \citeac{monadic-parsing}, using a premade library is usually more advantageous, because of e.g. reduced effort, increased functionality, optimized performance and better documentation.
The extra effort to learn the library is paid off by these advantages.
In Haskell this is mostly done by providing monadic combinators to hold up extra information about the parsing state, and results in very elegant solutions \citeac{monadic-parsing}.
Combinator libraries are often called Embedded Domain Specific Languages (EDSL), as opposed to an external, stand-alone DSL.

The parsers built in Haskell are mostly recursive descent parsers, wherein the parser runs top-down from a set of recursive calls.
The program structure is then closely related to the production rules, supporting the readability of the program structure.

These parsers analyze the input text from \underline{L}eft to right and choose the \underline{L}eftmost derivation in the grammar.
Such parsers are called therefore LL parsers.

~\\
However, there are limitations related to recursive descent parsers.
For instance, a common kind of production rule is a left recursive one, e.g. \texttt{term $\rightarrow$ term `$+$' term $|$ digit}.
In this case, the first thing the parser would do is call itself, resulting in an infinite loop.
Fortunately, left recursive grammars can be converted into right recursive ones \citeac{remove-left}.

Therefore, LL parsers may require exponential time to run and are not able to guarantee termination.
In order to guarantee termination and linear execution time, a recursive descent parser must be able to recognize which production rule to use by reading only limited amount of tokens.
This is only possible for the class of unambiguous grammars without left recursion.

~\\
\dict{LL(k)-grammar}{A grammar that can be parsed by an LL($k$)-parser}%
\dict{LL(k)-parser}{Top-down parser that parses from left to right, performing the leftmost derivation with a maximum $k$-tokens of look-ahead}%
The EBNF for the ADL-language has no left recursion.
This grammar can therefore be called an LL($k$)-grammar, for which an LL($k$)-parser can be created.
The $k$ between the parenthesis means that this parser needs a maximum of $k$ tokens of look-ahead in order to choose a production rule.
The grammar is currently ambiguous, however it is expected that it can be refactored so that the ambiguity is removed.

\subsubsection{Parser generators}
As mentioned, another approach for building a parser is to specify the software's grammar in a specific notation and use a parser generator to create the actual parser source code.
In the domain of context-free grammars, a widely used grammar notation is the Backus-Naur Form (BNF).

\dict{Happy Parser Generator}{Parser generator system for Haskell. \url{https://www.haskell.org/happy/}}%
This research is focused in the Happy parser generator, which is part of the Haskell Platform since 2001.
Happy inputs a file containing an annotated BNF specification of a grammar and produces a Haskell module with a parser for that grammar.
Since it is possible to convert EBNF to BNF \citenac{bnf-ebnf}, specifying a Happy parser should not involve a lot of effort.
It is important to know, however, that besides converting the EBNF to BNF, the annotation still requires effort and knowledge acquisition.

\dict{LR parser}{Top-down parser that parses from left to right, performing the rightmost derivation}%
A parser generator is able to execute statical analysis on the input grammar.
Besides, generators are often able to recognize more complicated grammars by running \underline{L}eft-to-right, and picking the \underline{R}ightmost derivation, being called therefore an LR parser.

\dict{LALR parser}{LR parser with look-ahead}%
An LR parser with \underline{L}ook-\underline{A}head is called an LALR parser.
By performing the rightmost derivation of the production rules, an LALR parser is able to recognize more complex grammars.
However, its workings are quite unintuitive, and understanding such parsers can be very hard.
That is exactly why LALR parsers are usually generated instead of built by hand.

Since understanding LALR parsers is hard, the syntax errors caused by incorrect input may be much harder to pinpoint and understand.
The errors generated by LALR parsers are often not in high-level terms that the end users can understand.

\dict{GHC}{Glasgow Haskell Compiler}%
\dict{Hugs}{Haskell Compiler}%
\dict{YACC}{Yet Another Compiler Compiler}%
\dict{Hellium}{Haskell Compiler. \url{www.cs.uu.nl/helium}}%
\dict{GCC}{Gnu Compiler Collection. \url{https://gcc.gnu.org/}}%
Haskell compilers GHC and Hugs are both built with LALR generated parsers: Hugs is written in YAC and GHC is built with Happy.
Later on, the Helium compiler was created for classroom-use because the mentioned Haskell compilers were not user friendly \citeac{helium-parser}.
Other examples are the GCC compilers for C and C++, that started as LALR generated compilers and were remade to be recursive-descent parsers.

Although it is harder to understand its workings, the resulting source code for the generators is simpler and easier to maintain, as can be seen in Hulette's examples \citenac{parser-examples}.

\subsubsection{Conclusion}
In the context of the new Ampersand parser, some advantages of building the parser in Haskell instead of using a generator, are:
\begin{description}
	\item[Flexibility] The programming language gives much more flexibility in coping with context-sensitive grammars.
	\item[Building] The process is simpler since it is unnecessary to run a separate program to generate the parser.
	\item[Language] Both the customer and the project members feel more comfortable working in Haskell than in an unknown DSL.
	\item[Errors] The main objective of the project is giving useful feedback in the new Ampersand parser, and this seems much easier to achieve with a handwritten parser.
\end{description}

\noindent
On the other hand, the advantages of using a parser generator, instead of handwriting the code, are:
\begin{description}
	\item[Optimizations] Because the parser is generated on-the-fly, the generator can apply optimizations that would otherwise be hard to implement.
	\item[Performance] Bottom-up parsers are much more efficient because they are able to pack the code into state machines.
		This is even more valid when many parsing alternatives are available.
	\item[Static analysis] The generator is able to do a lot more static analysis, while a library is only executed at run-time.
    E.g. programmers may only know of left recursions and non-terminations by testing the parser.
	\item[Documentation] Since the DSL is basically annotated BNF, keeping the syntax diagrams up to date is much easier.
\end{description}

\noindent
From the above advantages and disadvantages, it is clear that no universal truth exists in these matters.
Although it is a difficult choice, the error messages are indeed the most important project target, so writing the parser by hand is the advised option.
This choice also means that it keeps on being a task of the developers to update the documentation, e.g. the syntax diagrams that are currently not up-to-date.

\subsection{Combinator libraries}
In the previous section, the choice to use a combinator library has been taken.
In this section, two libraries will be compared: the Utrecht University parser combinator library (uu-parsinglib) and Parsec.
Other libraries (e.g. Attoparsec, Polyparse) are out of the scope of this research.

\subsection{Utrecht University Parsing Library}
\dict{uu-parsinglib}{New version of the uulib}%
\dict{uulib}{Haskell parsing library from the Utrecht University. \url{http://foswiki.cs.uu.nl/foswiki/HUT/ParserCombinators}}%
\dict{GADT}{Generalized Algebraic Datatypes for Haskell}%
The uu-parsinglib is a combinator library created by Doaitse Swierstra in the Utrecht University.
This library is used in many mature projects and has more than 4 thousand downloads in the Hackage package manager.
There are two versions of this library:
\begin{itemize}
  \item The uulib library is older and more limited, dating back from 2005.
    It is used in most of the projects distributed by the Utrecht University, and in the current Ampersand parser.
  \item The new version, named uu-parsinglib, dates from 2008, has several improvements and much simpler internals because of GATD.
    This version is considered in the rest of the document because of its performance \citenac{benchmark} and the author's recommendation \citenac{uulib-parsinglib}.
\end{itemize}
%
The documentation is mainly in Haddock format and in a paper from 2009 \citeac{uu-doc}.
The implementation is open source.
The new version of the uu-parsinglib provides combinators that include error correction and a monadic interface.
Errors are recognized and corrected automatically if the programmer wants so, but the error reporting is customizable.
It also supports grammars that are not context-free and even ambiguous grammars (provided the user accepts exponential run-time).

Finally, the uu-parsinglib runs online, i.e. it returns parts of the parsing three as soon as they are ready.
This gives programmers the ability to do lazy parsing.

\subsection{Parsec}
\dict{Parsec}{Haskell monadic parsing combinator library written by Daan Leijen. \url{https://www.haskell.org/haskellwiki/Parsec}}%
Parsec is a monadic parsing combinator library created by Daan Leijen, while also working at the Utrecht University.
It seems to be the most popular combinator library in the Haskell community, with more than 200 thousand downloads in the Hackage package manager.

Parsec is designed to be simple, safe and well documented industrial parser library.
Besides, there has also been some work done on the performance and error messages.
The documentation of Parsec and its documentation tends to be better than that of the uu-parsinglib because of a larger user base.

%todo: this section is very empty
%todo: https://www.haskell.org/haskellwiki/Parsec
%todo: http://stackoverflow.com/questions/19208231/attoparsec-or-parsec-in-haskell/19213247#19213247

\subsection{Monadic vs. applicative interfaces}
Monads allow sequences and state to be saved during the parsing, and had become the most common way of building Haskell parsers.
Until, in a paper from Swierstra \citeac{error-correcting}, a parsing library was published with an alternative interface.
McBride and Paterson presented this alternative as a generalization of monads, calling it `applicative functors' or `idioms'.
Applicative interfaces are less convenient than monads but are more widely applicable \citeac{applicative}.

Applicative parsers do not depend on the run-time values -- they are not dependent on the context.
This means that it is then possible to analyze and optimize the parser before executing it.
Swierstra goes so far to say that this works as a run-time parser generator \citeac{error-correcting}.
On the other hand, the lack of context means that only context-free languages can be implemented this way \citeac{parsec}.

Both the uu-parsinglib and Parsec have monadic and applicative interfaces.
In the applicative interface, the uu-parsinglib also adds error correction:
After detecting an error, the library will correct it by adding or deleting tokens.
It then generates an appropriate error message and continues with the rest of the program.
By using this interface, the parsing will thus always succeed.

\subsection{Conclusion}
The following differences have been found between the two considered libraries:
\begin{description}
	\item[Documentation] The documentation of Parsec seems to be more extended and well-maintained.
		Several Parsec tutorials can be found on the internet (e.g. \citenac{using-parsec}).
		On the other hand, the uu-parsinglib's documentation is mostly generated from code annotations.
	\item[Support] Since Parsec is much more used, online support can be more easily found.
		For example, the website Stack Overflow currently has 14 questions about the uu-parsinglib and 301 about Parsec.
	\item[Static checking] None of the libraries is able to do static checking.
		However, the uu-parsinglib has more possibilities of grammar analysis in its applicative interface.
	\item[Precedences] The Ampersand parser is currently built with the uu-parsinglib with great satisfaction.
		This both means that the library has enough features and that it is known by the other Ampersand developers.
	\item[Error reporting] No literature has been found with a comparison of the errors generated by the libraries.
		However, many publications affirm that the generated errors from both libraries are great \citeac{helium-parser,uu-doc,error-correcting,parsec}.
	\item[Error recovery] When a parsing error is found, a Parsec parser stops immediately.
		A parser built with uu-parsinglib, however, corrects the error and continues parsing.
		Error correction is good because the parser always succeeds.
		On the other hand, a big list of errors can also overwhelm the user \citeac{heeren-error}.
		Finally, to perform the corrections, the parser needs to make assumptions based e.g. on statistics;
		these assumptions cannot always be correct.
	\item[Fine-tuning] According to the Helium development team, Parsec's possibilities for error fine-tuning are greater \citeac{helium-parser}.
		However, to apply optimizations it is necessary to know the internal workings of the parser \citeac{uu-doc}.
	\item[Backtracking] Parsec works with more traditional backtracking algorithms \citeac{parsec} that can often lead to high space consumption \citeac{uu-doc}.
		Backtracking must be manually activated, though, with it's \textit{try} combinator.
    This combinator is considered harmful and can be easily misused \citenac{try-harmful}.
		The uu-parsinglib, on the other hand, uses breadth-first lazy parsing \citeac{uu-doc} so such combinator is not necessary.
		%todo: http://osdir.com/ml/haskell-cafe@haskell.org/2012-01/msg00566.html
    
	\item[Performance] The Parsec library seems to have better performance \citenac{benchmark}, but the difference is small and is not expected to make a considerable difference in the small ADL scripts.
	\item[Maintainability] No significant difference has been found in the maintainability of the two analyzed libraries.
		Note that the programmers working on Ampersand are already familiar with the uu-parsinglib.
		On the other hand, there is more support and documentation available for Parsec, so it can also be seen as more future-proof.
		The responsibility for the maintainability still lies on the hands of the programmers building the parser.
	\item[Origin] Both libraries are originated at the Utrecht University.
		In 2003, a Haskell compiler focused on user friendliness, Helium, was published from the same university.
		Knowing both libraries very well, the authors made the choice to use Parsec because of the possibilities of error customization \citeac{helium-parser}.
\end{description}
%
Considering these differences, a deeper analysis of error messages is given in the next section.
The actual advice on the library choice is delayed until \autoref{sec:conclusion}.
