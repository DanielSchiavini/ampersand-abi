% !TEX root = ../Parsing.tex

\section{Haskell parsing libraries}
\label{sec:libraries}

\subsection{Parsing remarks}
\dict{Lexical analysis}{Separating text into tokens}%
\dict{Lexer}{Software that does the lexical analysis}%
\dict{Alex}{Lexer included in the Haskell Platform}%
Parsing is sometimes divided into two stages: lexical analysis (separating the source text into tokens) and parsing itself (constructing a parse tree).
Tools such as the ones analyzed here can perform both lexical analysis and parsing.
However, sometimes the tools can be more efficient when supported by a separate Lexer (e.g. Alex).

Grammars associated with a formal language are described as a set of production rules.
Since these rules are formally defined, a series of mathematical constructions can be used to manipulate and describe the grammar.

\dict{ADL}{Ampersand Definition Language}%
\dict{BNF}{Backus-Naur Form, a meta-syntax notation for expressing context-free grammars}%
\dict{EBNF}{Extended Backus-Naur Form, an extension on BNF}%
The Ampersand Definition Language (ADL) is specified in a grammar in the Extended Backus-Naur Form (EBNF).
Even though it is known that the grammar is not up to date, this article assumes the updated version will not fundamentally be different than the specified grammar.

\subsection{Generators vs. combinators}
\dict{DSL}{Domain specific language}%
Generally, there are two options for implementing a parser:
The first option is to implement the parser in the language of choice, i.e. Haskell for this project.
Another possibility is to use a domain-specific-language (DSL) to describe the grammar, and let a separate software generate the actual parsing code.
The two approaches and their advantages and disadvantages are described in this section.

\subsubsection{Parsing libraries}
When programmers go down the path of building a parser directly in Haskell, building up a set of functions that support parsing is a natural consequence.
Although it's possible to build these functions for each and every project \cite{monadic-parsing}, using a premade library has several advantages, e.g. reduced effort, increased functionality, optimized performance and better documentation.
The extra effort to learn the library is paid off by these advantages.
In Haskell this is mostly done by providing monadic combinators to hold up extra information about the parsing state, and results in very elegant solutions \cite{monadic-parsing}.

The parsers built in Haskell are mostly recursive descent parsers, wherein the parser runs top-down from a set of recursive calls.
The program structure is then closely related to the production rules, supporting the readability of the program structure.

These parsers analyze the input text from \underline{L}eft to right and choose the \underline{L}eftmost derivation in the grammar.
Such parsers are called therefore LL parsers.

~\\
However, there are limitations related to recursive descent parsers.
For instance, a common kind of production rule is a left recursive one, e.g. \texttt{term $\rightarrow$ term `$+$' term $|$ number}.
In this case, the first thing the parser would do is call itself, resulting in an infinite loop.
Gladly, any left recursive grammar can be converted into a right recursive one \cite{remove-left}.

Therefore, LL parsers may require exponential time to run and are not able to guarantee termination.
In order to guarantee termination and linear execution time, a recursive descent parser must be able to recognize which production rule to use by reading only limited amount of tokens.
This is only possible for the class of unambiguous grammars without left recursion.

~\\
\dict{LL(k)-grammar}{A grammar that can be parsed by an LL($k$)-parser}%
\dict{LL(k)-parser}{Top-down parser that parses from left to right, performing the leftmost derivation with a maximum $k$-tokens of look-ahead}%
The EBNF for the ADL-language is not ambiguous and has no left recursion.
This grammar can therefore be called an LL($k$)-grammar, for which an LL($k$)-parser can be created.
The $k$ between parenthesis means that this parser needs a maximum of $k$ tokens of look-ahead in order to choose a production rule.

\subsubsection{Parser generators}
As mentioned, another approach for building a parser is to specify the software's grammar in a specific notation and use a parser generator to create the actual parser source code.
In the domain of context-free grammars, a widely used grammar notation is the Backus-Naur Form (BNF).

\dict{Happy Parser Generator}{Parser generator system for Haskell. \url{https://www.haskell.org/happy/}}%
This research is focused in the Happy parser generator, which is part of the Haskell Platform since 2001.
Happy inputs a file containing an annotated BNF specification of a grammar and produces a Haskell module with a parser for the grammar.
Since it is possible to convert EBNF to BNF \cite{convert-ebnf,bnf-ebnf}, a Happy parser should not involve a lot of effort.
It is important to know, however, that besides converting the EBNF to BNF, the annotation still requires effort and knowledge acquisition.

\dict{LR parser}{Top-down parser that parses from left to right, performing the rightmost derivation}%
A parser generator is able to execute many more statical analysis on the input grammar.
Besides, they are often able to recognize more complicated grammars by running \underline{L}eft-to-right, and picking the \underline{R}ightmost derivation, being called therefore an LR parser.

\dict{LALR parser}{LR parser with look-ahead}%
An LR parser with \underline{L}ook-\underline{A}head is called an LALR parser.
By performing the rightmost derivation of the production rules, an LALR parser is able to recognize more complex grammars.
However, it's workings are quite unintuitive, and understanding such parsers can be very hard.
That's why LALR parsers are usually generated instead of built by hand.

Since understanding LALR parsers is hard, the syntax errors caused by incorrect input may be much harder to pinpoint and understand.
The errors generated by LALR parsers are often not in high-level terms that the end users can understand.

\dict{GHC}{Glasgow Haskell Compiler}%
\dict{Hugs}{Haskell Compiler}%
\dict{YACC}{Yet Another Compiler Compiler}%
\dict{Hellium}{Haskell Compiler}%
\dict{GCC}{Gnu Compiler Collection}%
Haskell compilers GHC and Hugs are both built with LALR generated parsers: Hugs is written in YACC \cite{hugs-parser} and GHC is built with Happy \cite{ghc-parser}.
Later on, the Helium compiler was created for classroom-use because the mentioned Haskell compilers were not user friendly \cite{helium-parser}.
Other examples are the GCC C and C++ compilers, that started as LALR generated compilers and were remade to be recursive-descent parsers \cite{gcc-c-parser} \cite{gcc-cpp-parser}.

On the other hand, resulting source code is simpler and easier to maintain, as can be seen in \cite{parser-examples}.

\subsubsection{Conclusion}
In the context of the new Ampersand parser, Some advantages of building the parser in Haskell, instead of using a generator, are:
\begin{description}
	\item[Flexibility] The programming language gives much more flexibility in coping with context-sensitive grammars.
	\item[Building] The process is simpler since it is unnecessary to run a separate program to generate the parser.
	\item[Language] Both the customer and the project members feel more comfortable working in Haskell then in an unknown DSL.
	\item[Errors] The main objective of the project is giving useful feedback in the new Ampersand parser, and this seems much easier to achieve with a handwritten parser.
\end{description}

\noindent
On the other hand, the advantages of using a parser generator, instead of handwriting the code, are:
\begin{description}
	\item[Optimizations] Because the parser is generated on-the-fly, the generator can apply optimizations that would otherwise be hard to implement.
	\item[Performance] Bottom-up parsers are much more efficient because they are able to pack the code into state machines.
		This is even more valid when many parsing alternatives are available.
	\item[Static analysis] The generator is able to do a lot more static analysis, while a library is only executed during the runtime.
    E.g. programmers will only know of left recursions and non-terminations by testing the parser.
	\item[Documentation] Since the DSL basically annotated BNF, keeping the syntax diagrams up to date is much easier.
\end{description}

\noindent
From the above advantages and disadvantages, it is clear that no universal truth exists in these matters.
Although it is a difficult choice, the error messages are indeed the most important project target, so writing the parser by hand is the advised option.

\subsection{Combinator libraries}
In the previous section, the choice to use a combinator library has been taken.
In this section, two libraries will be compared: the Utrecht University parser combinator library (uu-parsinglib) and Parsec.

\subsection{Utrecht University Parsing Library}
\dict{uu-parsinglib}{Haskell parsing library from the Utrecht University. \url{http://foswiki.cs.uu.nl/foswiki/HUT/ParserCombinators}}%
The uu-parsinglib is a library created by Doaitse Swierstra in the Utrecht University.
This library is used in many mature projects.
The current Ampersand parser is also built with the previous version of the uu-parsinglib.
The new version has serveral improvements, mainly in performance \cite{parse-benchmark}.
It currently has more than 4 thousand downloads in the Hackage package manager.

The documentation is mainly in Haddock format and in a paper from 2009 \cite{uu-doc}.
The implementation is open source.
The new version of the uu-parsinglib provides combinators that include error correction in a monadic interface.
Errors are recognized and corrected automatically if the programmers want so, but the reporting is customizable.
It also supports grammars that are not context-free and even ambiguous grammars (provided the user accepts exponential runtime).

Finally, the uu-parsinglib runs online, i.e. it returns parts of the parsing three as soon as they are ready.
This gives programmers the ability to do lazy parsing.

\subsection{Parsec}
\dict{Parsec}{Haskell monadic parsing combinator library written by Daan Leijen. \url{https://www.haskell.org/haskellwiki/Parsec}}%
Parsec is a monadic parsing combinator library created by Daan Leijen
It seems to be the most popular combinator library in the Haskell community, with more than 200 thousand downloads in the Hackage package manager.

Parsec is designed to be simple, safe and well documented industrial parser library.
Besides, there has also been some work done on the performance and error messages.
The documentation of Parsec tends to be better than that of the uu-parsinglib because of a larger user base.

%todo: https://www.haskell.org/haskellwiki/Parsec
%todo: http://stackoverflow.com/questions/19208231/attoparsec-or-parsec-in-haskell/19213247#19213247

\subsection{Other libraries}
Other libraries (e.g. Attoparsec, Polyparse) are out of the scope of this research.

\subsection{Monadic vs. arrow interfaces}
Monads have become the standard way of building Haskell parsers.
However, in a paper from Swierstra \cite{}, the uu-parsinglib was presented with an alternative interface.
Hughes presented this alternative as a generalization of monads, calling it `arrows' \cite{monad-arrows}.

Arrows are less convenient than monads but are much widely applicable \cite{monad-arrows}.
Monads would still be used for state passing and other constructions, but the continuations would be carried over to arrows.

\subsection{Feature comparison}
The following differences have been found between the two considered libraries:
\begin{description}
	\item[Documentation]
	\item[Static checking]
	\item[Precedences]
	\item[Features]
	\item[Error reporting]
	\item[Error correction]
	\item[Maintainability] No significant difference has been found in the maintainability of the two analyzed libraries.
		Note that the programmers working on Ampersand are already familiar with the uu-parsinlib.
		On the other hand, there is more support and documentation available for Parsec, so it can also be seen as more future-proof.
\end{description}

\subsection{Conclusion}
%Another vote for uu-parsinglib. Our team switched from Parsec to uu-parsinglib a bit more than a year ago, and we haven't looked back. No explicit 'try' combinator needed, ability to do lazy parsing, and error correction mean that the fundamentals are more powerful than those of Parsec (even if the end-user niceties - documentation,pre-provided parsers for lexing etc aren't yet quite as good - but getting better).

