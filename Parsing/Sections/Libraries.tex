% !TEX root = ../Parsing.tex

\section{Haskell parsing libraries}
\label{sec:libraries}

\subsection{Parsing remarks}
\dict{Lexical analysis}{Separating text into tokens}%
\dict{Lexer}{Software that does the lexical analysis}%
\dict{Alex}{Lexer included in the Haskell Platform}%
Parsing is sometimes divided into two stages: lexical analysis (separating the source text into tokens) and parsing itself (constructing a parse tree).
Tools such as the ones analyzed here can perform both lexical analysis and parsing.
However, sometimes the tools can be more efficient when supported by a separate Lexer (e.g. Alex).

Grammars associated with a formal language are described as a set of production rules.
Since these rules are formally defined, a series of mathematical constructions can be used to manipulate and describe the grammar.

\dict{ADL}{Ampersand Definition Language}%
\dict{BNF}{Backus-Naur Form, a meta-syntax notation for expressing context-free grammars}%
\dict{EBNF}{Extended Backus-Naur Form, an extension on BNF}%
The Ampersand Definition Language (ADL) is specified in a grammar in the Extended Backus-Naur Form (EBNF).
Even though it is known that the grammar is not up to date, this article assumes the updated version will not fundamentally be different than the specified grammar.

\subsection{Generators vs. combinators}
\dict{DSL}{Domain specific language}%
Generally, there are two options for implementing a parser:
The first option is to implement the parser in the language of choice, i.e. Haskell for this project.
Another possibility is to use a domain-specific-language (DSL) to describe the grammar, and let a separate software generate the actual parsing code.
The two approaches and their advantages and disadvantages are described in this section.

\subsubsection{Parsing libraries}
When programmers go down the path of building a parser directly in Haskell, building up a set of functions that support parsing is a natural consequence.
Although it's possible to build these functions for each and every project \cite{monadic-parsing}, using a premade library has several advantages, e.g. reduced effort, increased functionality, optimized performance and better documentation.
The extra effort to learn the library is paid off by these advantages.
In Haskell this is mostly done by providing monadic combinators to hold up extra information about the parsing state, and results in very elegant solutions \cite{monadic-parsing}.

The parsers built in Haskell are mostly recursive descent parsers, wherein the parser runs top-down from a set of recursive calls.
The program structure is then closely related to the production rules, supporting the readability of the program structure.

These parsers analyze the input text from \underline{L}eft to right and choose the \underline{L}eftmost derivation in the grammar.
Such parsers are called therefore LL parsers.

~\\
However, there are limitations related to recursive descent parsers.
For instance, a common kind of production rule is a left recursive one, e.g. \texttt{term $\rightarrow$ term `$+$' term $|$ number}.
In this case, the first thing the parser would do is call itself, resulting in an infinite loop.
Gladly, any left recursive grammar can be converted into a right recursive one \cite{remove-left}.

Therefore, LL parsers may require exponential time to run and are not able to guarantee termination.
In order to guarantee termination and linear execution time, a recursive descent parser must be able to recognize which production rule to use by reading only limited amount of tokens.
This is only possible for the class of unambiguous grammars without left recursion.

~\\
\dict{LL(k)-grammar}{A grammar that can be parsed by an LL($k$)-parser}%
\dict{LL(k)-parser}{Top-down parser that parses from left to right, performing the leftmost derivation with a maximum $k$-tokens of look-ahead}%
The EBNF for the ADL-language is not ambiguous and has no left recursion.
This grammar can therefore be called an LL($k$)-grammar, for which an LL($k$)-parser can be created.
The $k$ between parenthesis means that this parser needs a maximum of $k$ tokens of look-ahead in order to choose a production rule.

\subsubsection{Parser generators}
As mentioned, another approach for building a parser is to specify the software's grammar in a specific notation and use a parser generator to create the actual parser source code.
In the domain of context-free grammars, a widely used grammar notation is the Backus-Naur Form (BNF).

\dict{Happy Parser Generator}{Parser generator system for Haskell. \url{https://www.haskell.org/happy/}}%
This research is focused in the Happy parser generator, which is part of the Haskell Platform since 2001.
Happy inputs a file containing an annotated BNF specification of a grammar and produces a Haskell module with a parser for the grammar.
Since it is possible to convert EBNF to BNF \cite{convert-ebnf,bnf-ebnf}, a Happy parser should not involve a lot of effort.
It is important to know, however, that besides converting the EBNF to BNF, the annotation still requires effort and knowledge acquisition.

\dict{LR parser}{Top-down parser that parses from left to right, performing the rightmost derivation}%
A parser generator is able to execute many more statical analysis on the input grammar.
Besides, they are often able to recognize more complicated grammars by running \underline{L}eft-to-right, and picking the \underline{R}ightmost derivation, being called therefore an LR parser.

\dict{LALR parser}{LR parser with look-ahead}%
An LR parser with \underline{L}ook-\underline{A}head is called an LALR parser.
By performing the rightmost derivation of the production rules, an LALR parser is able to recognize more complex grammars.
However, its workings are quite unintuitive, and understanding such parsers can be very hard.
That's why LALR parsers are usually generated instead of built by hand.

Since understanding LALR parsers is hard, the syntax errors caused by incorrect input may be much harder to pinpoint and understand.
The errors generated by LALR parsers are often not in high-level terms that the end users can understand.

\dict{GHC}{Glasgow Haskell Compiler}%
\dict{Hugs}{Haskell Compiler}%
\dict{YACC}{Yet Another Compiler Compiler}%
\dict{Hellium}{Haskell Compiler}%
\dict{GCC}{Gnu Compiler Collection}%
Haskell compilers GHC and Hugs are both built with LALR generated parsers: Hugs is written in YACC \cite{hugs-parser} and GHC is built with Happy \cite{ghc-parser}.
Later on, the Helium compiler was created for classroom-use because the mentioned Haskell compilers were not user friendly \cite{helium-parser}.
Other examples are the GCC C and C++ compilers, that started as LALR generated compilers and were remade to be recursive-descent parsers \cite{gcc-c-parser} \cite{gcc-cpp-parser}.

On the other hand, resulting source code is simpler and easier to maintain, as can be seen in \cite{parser-examples}.

\subsubsection{Conclusion}
In the context of the new Ampersand parser, Some advantages of building the parser in Haskell, instead of using a generator, are:
\begin{description}
	\item[Flexibility] The programming language gives much more flexibility in coping with context-sensitive grammars.
	\item[Building] The process is simpler since it is unnecessary to run a separate program to generate the parser.
	\item[Language] Both the customer and the project members feel more comfortable working in Haskell then in an unknown DSL.
	\item[Errors] The main objective of the project is giving useful feedback in the new Ampersand parser, and this seems much easier to achieve with a handwritten parser.
\end{description}

\noindent
On the other hand, the advantages of using a parser generator, instead of handwriting the code, are:
\begin{description}
	\item[Optimizations] Because the parser is generated on-the-fly, the generator can apply optimizations that would otherwise be hard to implement.
	\item[Performance] Bottom-up parsers are much more efficient because they are able to pack the code into state machines.
		This is even more valid when many parsing alternatives are available.
	\item[Static analysis] The generator is able to do a lot more static analysis, while a library is only executed during the run-time.
    E.g. programmers will only know of left recursions and non-terminations by testing the parser.
	\item[Documentation] Since the DSL basically annotated BNF, keeping the syntax diagrams up to date is much easier.
\end{description}

\noindent
From the above advantages and disadvantages, it is clear that no universal truth exists in these matters.
Although it is a difficult choice, the error messages are indeed the most important project target, so writing the parser by hand is the advised option.

\subsection{Combinator libraries}
In the previous section, the choice to use a combinator library has been taken.
In this section, two libraries will be compared: the Utrecht University parser combinator library (uu-parsinglib) and Parsec.

\subsection{Utrecht University Parsing Library}
\dict{uu-parsinglib}{Haskell parsing library from the Utrecht University. \url{http://foswiki.cs.uu.nl/foswiki/HUT/ParserCombinators}}%
The uu-parsinglib is a combinator library created by Doaitse Swierstra in the Utrecht University.
This library is used in many mature projects.
The current Ampersand parser is also built with the previous version of the uu-parsinglib.
The new version has several improvements, mainly in performance \cite{benchmark}.
It currently has more than 4 thousand downloads in the Hackage package manager.

The documentation is mainly in Haddock format and in a paper from 2009 \cite{uu-doc}.
The implementation is open source.
The new version of the uu-parsinglib provides combinators that include error correction in a monadic interface.
Errors are recognized and corrected automatically if the programmers want so, but the reporting is customizable.
It also supports grammars that are not context-free and even ambiguous grammars (provided the user accepts exponential run-time).

Finally, the uu-parsinglib runs online, i.e. it returns parts of the parsing three as soon as they are ready.
This gives programmers the ability to do lazy parsing.

\subsection{Parsec}
\dict{Parsec}{Haskell monadic parsing combinator library written by Daan Leijen. \url{https://www.haskell.org/haskellwiki/Parsec}}%
Parsec is a monadic parsing combinator library created by Daan Leijen.
It seems to be the most popular combinator library in the Haskell community, with more than 200 thousand downloads in the Hackage package manager.

Parsec is designed to be simple, safe and well documented industrial parser library.
Besides, there has also been some work done on the performance and error messages.
The documentation of Parsec and its documentation tends to be better than that of the uu-parsinglib because of a larger user base.

%todo: https://www.haskell.org/haskellwiki/Parsec
%todo: http://stackoverflow.com/questions/19208231/attoparsec-or-parsec-in-haskell/19213247#19213247

\subsection{Other libraries}
Other libraries (e.g. Attoparsec, Polyparse) are out of the scope of this research.

\subsection{Monadic vs. arrow interfaces}
Monads allow sequences and state to be saved during the parsing, and had become the most common way of building Haskell parsers.
Until, in a paper from Swierstra \cite{error-correcting}, a parsing library was presented with an alternative interface.
Hughes presented this alternative as a generalization of monads, calling it `arrows' \cite{monad-arrows}.

Arrows are less convenient than monads but are much widely applicable \cite{monad-arrows}.
Monads would still be used for state passing and other constructions, but the continuations would be carried over to arrows.

Arrow-style parsers do not depend on the run-time values -- they are not dependent on the context.
This means that it is then possible to analyze and optimize the parser before executing it.
Swierstra goes so far to say that this works a run-time parser generator \cite{error-correcting}.
On the other hand, the lack of context means that only context-free languages can be implemented this way \cite{parsec}.

The uu-parsinglib allows both monadic and arrow-style parsing, while Parsec only has a monadic interface.
In the arrow-style interface, the uu-parsinglib also adds error correction:
After detecting an error, the library will correct it by adding or deleting tokens.
It then generates an appropriate error message and continues with the rest of the program.
By using this interface, the parsing will thus always succeed.

%todo: http://worldbusiness.org/wp-content/uploads/2012/10/arrows-and-idioms2.pdf
%todo: http://marc.info/?l=haskell-cafe&m=128039136131494

\subsection{Conclusion}
The following differences have been found between the two considered libraries:
\begin{description}
	\item[Documentation] The documentation of Parsec seems to be more extended and well-maintained.
		Several tutorials can be found on the internet (e.g. \cite{using-parsec}).
		On the other hand, the uu-parsinglib's documentation is mostly generated from code annotations.
	\item[Support] Since Parsec is much more used and online support can be more easily found.
		For example, the website StackOverflow currently has 14 questions about the uu-parsinglib and 301 about Parsec.
	\item[Static checking] None of the libraries is able to do static checking.
		However, the uu-parsinglib has more possibilities of grammar analysis in its arrow-style interface.
	\item[Precedences] The Ampersand parser is currently built with the uu-parsinglib with great satisfaction.
		This both means that the library is sufficient and that it is known by the other Ampersand programmers.
	\item[Error reporting] No literature has been found with a comparison of the errors generated by the libraries.
		However, many publications affirm that the generated errors from both libraries are great.
	\item[Error correction] When a parsing error is found, a Parsec parser stops immediately.
		A parser built with uu-parsinglib, however, corrects the error and continues parsing.
		Error correction is good because the parser always succeeds.
		On the other hand, a big list of errors can also overwhelm the user \cite{heeren-error}.
		Finally, to perform the corrections, the parser needs to make assumptions based e.g. on statistics.
		These assumptions cannot always be correct.
	\item[Fine-tuning] According to the Helium development team, Parsec's possibilities for error fine-tuning are greater \cite{helium-parser}.
		However, to apply optimizations it is necessary to know the internal workings of the parser \cite{uu-doc}.
	\item[Backtracking] Parsec works with more traditional backtracking algorithms \cite{parsec} that can often lead to high space consumption \cite{uu-doc}.
		This is however
	\item[Performance] The Parsec library seems to have better performance \cite{benchmark}, but the difference is small and is not expected to make a considerable difference in the small ADL scripts.
	\item[Try operator] In order to allow backtracking, Parsec code uses the try-function, which is considered harmful and can be easily misused \cite{try-harmful}.
		This keyword is totally unnecessary in the uu-parsinglib because it uses breadth-first lazy parsing.
		%todo: http://osdir.com/ml/haskell-cafe@haskell.org/2012-01/msg00566.html
	\item[Maintainability] No significant difference has been found in the maintainability of the two analyzed libraries.
		Note that the programmers working on Ampersand are already familiar with the uu-parsinglib.
		On the other hand, there is more support and documentation available for Parsec, so it can also be seen as more future-proof.
	\item[Origin] Both libraries are originated at the Utrecht University.
		In 2003, a Haskell compiler focused on user friendliness, Helium, was published from the same university.
		Knowing both libraries very well, the authors made the choice to use Parsec because of the possibilities of error customization \cite{helium-parser}.
\end{description}
%
Considering these differences, a deeper analysis of error messages is given.
The actual library choice is delayed until \autoref{sec:conclusion}.
